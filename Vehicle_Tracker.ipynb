{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ucalegon/pythoconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python -W ignore::DeprecationWarning\n",
    "\n",
    "# General Utilities\n",
    "import glob, pickle, os, time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Image processing & analysis functions\n",
    "from skimage.feature import hog\n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage.color import rgb2hsv, rgb2luv, rgb2ycbcr\n",
    "from skimage.exposure import rescale_intensity, equalize_adapthist\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from scipy.ndimage.measurements import label\n",
    "\n",
    "# Import classifier\n",
    "#from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "import imageio\n",
    "imageio.plugins.ffmpeg.download()\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Import Tracker Class for keeping track of heatmaps\n",
    "from tracker import Tracker\n",
    "\n",
    "# Supress warnings (generated primarily by xgb)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert images from RGB to specified color_map\n",
    "def rgb_convert(img, color_map):\n",
    "    \n",
    "    if color_map == 'HSV':\n",
    "        img_convert = rgb2hsv(img)\n",
    "    elif color_map == 'LUV':\n",
    "        img_convert = rgb2luv(img)\n",
    "    elif color_map == 'YCbCr':\n",
    "        img_convert = rgb2ycbcr(img)\n",
    "    \n",
    "    return img_convert\n",
    "\n",
    "# Pickle trained classifier\n",
    "def dump_classifier(clf, clf_name):\n",
    "    '''\n",
    "    Pickle classifier using clf_name\n",
    "    '''\n",
    "    if '.pickle' in clf_name:\n",
    "        pass\n",
    "    else:\n",
    "        clf_name += '.pickle'\n",
    "    with open('clfs/'+clf_name, 'wb') as f:\n",
    "        pickle.dump(clf, f)\n",
    "    f.close()\n",
    "\n",
    "    print('Classifier dumped to clfs/{}'.format(clf_name))\n",
    "\n",
    "    return\n",
    "\n",
    "# Load trained classifier\n",
    "def load_clf(clf_name):\n",
    "    with open('clfs/'+clf_name, 'rb') as f:\n",
    "        clf = pickle.load(f)\n",
    "    f.close()\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load pickled arrays of images & labels output from input_images.py\n",
    "def load_images_labels(processed_images = False):\n",
    "    if not processed_images:\n",
    "        with open('clf_images/all_vehicles_{}.pickle'.format(color_map), 'rb') as f:\n",
    "            all_vehicles = pickle.load(f)\n",
    "        f.close()\n",
    "    else:\n",
    "        with open('clf_images/all_vehicles_{}_processed.pickle'.format(color_map), 'rb') as f:\n",
    "            all_vehicles = pickle.load(f)\n",
    "        f.close()\n",
    "\n",
    "    with open('clf_images/all_vehicles_labels.pickle', 'rb') as f:\n",
    "        all_vehicles_labels = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    return all_vehicles, all_vehicles_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate Histogram of Oriented Gradients Features\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block,\n",
    "                        vis=False, feature_vec=True):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient,\n",
    "                                  pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block),\n",
    "                                  transform_sqrt=False,\n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:\n",
    "        features = hog(img, orientations=orient,\n",
    "                       pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block),\n",
    "                       transform_sqrt=False,\n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features\n",
    "\n",
    "# Generate spatial features\n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    color1 = cv2.resize(img[:,:,0], size).ravel()\n",
    "    color2 = cv2.resize(img[:,:,1], size).ravel()\n",
    "    color3 = cv2.resize(img[:,:,2], size).ravel()\n",
    "    return np.hstack((color1, color2, color3))\n",
    "\n",
    "# Generate color histogram features\n",
    "def color_hist(img, nbins=32, bins_range = (0, 256)):\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature extraction method for classifier training. \n",
    "def extract_features(imgs, spatial_size=(32, 32), hist_bins=32, hist_range=(0, 256), orient=12, pix_per_cell=8, cell_per_block=2, hog_channel='ALL'):\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for image in tqdm(imgs):\n",
    "        feature_image = np.copy(image)\n",
    "\n",
    "        # Call get_hog_features() with vis=False, feature_vec=True\n",
    "        if hog_channel == 'ALL':\n",
    "            hog_features = []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                hog_features.append(get_hog_features(feature_image[:,:,channel],\n",
    "                                    orient, pix_per_cell, cell_per_block,\n",
    "                                    vis=False, feature_vec=True))\n",
    "            hog_features = np.ravel(hog_features)\n",
    "        else:\n",
    "            hog_features = get_hog_features(feature_image[:,:,hog_channel], orient,\n",
    "                        pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "        # Apply bin_spatial() to get spatial color features\n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        # Apply color_hist() also with a color space option now\n",
    "        hist_features = color_hist(feature_image, nbins=hist_bins) #, bins_range=hist_range\n",
    "        # Append the new feature vector to the features list\n",
    "        features.append(np.concatenate((spatial_features, hist_features, hog_features)))\n",
    "    # Return list of feature vectors\n",
    "\n",
    "    feature_names = ['f_{}'.format(x) for x in range(len(features[0]))]\n",
    "    features_pd = pd.DataFrame(features, columns = feature_names)\n",
    "\n",
    "\n",
    "\n",
    "    return features_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train classifier\n",
    "def train_clf(features, labels, clf_type = 'xgb'):\n",
    "    \n",
    "    # Create train/test split for validation\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = 0.2, random_state = 42)\n",
    "    \n",
    "    # Fit, Transform & Dump scaler\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # XGBoost classifier\n",
    "    if clf_type == 'xgb':\n",
    "\n",
    "        clf = XGBClassifier()\n",
    "        clf_final = XGBClassifier()\n",
    "\n",
    "    # Gridsearch over Support Vector Machines using linear and polynomial kernels\n",
    "    elif clf_type == 'svc':\n",
    "\n",
    "        params = {\n",
    "                'kernel': ('linear', 'poly')\n",
    "                }\n",
    "\n",
    "        svc = SVC()\n",
    "        clf = GridSearchCV(svc, param_grid = params)\n",
    "        clf_final = GridSearchCV(svc, param_grid = params_)\n",
    "\n",
    "    # Train clf\n",
    "    t_0 = time.time()\n",
    "    print('training for validation...')\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    t_1 = time.time()\n",
    "    print('{} clf fit in {:.2f} s'.format(clf_type, t_1-t_0))\n",
    "    \n",
    "    # Predict and report clf quality\n",
    "    y_test_hat = clf.predict(X_test_scaled)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_test_hat)\n",
    "    f1 = f1_score(y_test, y_test_hat)\n",
    "    clf_report = classification_report(y_test, y_test_hat)\n",
    "\n",
    "    print('Accuracy = {}'.format(accuracy))\n",
    "    print('f1 Score = {}'.format(f1))\n",
    "    print('\\n')\n",
    "    print(clf_report)\n",
    "    \n",
    "    # After validation, train on whole training set\n",
    "    \n",
    "    scaler_final = StandardScaler().fit(features)\n",
    "    features_scaled = scaler_final.transform(features)\n",
    "    t_2 = time.time()\n",
    "    print('training for final...')\n",
    "    clf_final.fit(features_scaled, labels)\n",
    "    t_3 = time.time()\n",
    "    print('{} final clf fit in {:.2f} s'.format(clf_type, t_3-t_2))\n",
    "    \n",
    "    scaler_name = 'scaler_{}.pickle'.format(color_map)\n",
    "    dump_classifier(scaler_final, scaler_name)\n",
    "\n",
    "    return clf_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pipeline for training classifier\n",
    "def train_clf_pipeline():\n",
    "    images, labels = load_images_labels(processed_images = processed_images)\n",
    "    \n",
    "    # If pickled features array exists, load; else, create\n",
    "    if os.path.isfile('clf_images/all_vehicles_{}_features.pickle'.format(color_map)):\n",
    "        features_pd = pd.read_pickle('clf_images/all_vehicles_{}_features.pickle'.format(color_map))\n",
    "        print('features loaded from pickle')\n",
    "    else:\n",
    "        features_pd = extract_features(images)\n",
    "        features_pd.to_pickle('clf_images/all_vehicles_{}_features.pickle'.format(color_map))\n",
    "        print('features dumped to all_vehicles_{}_features.pickle'.format(color_map))\n",
    "\n",
    "    # Train and save classifier\n",
    "    clf = train_clf(features_pd, labels, clf_type = clf_type)\n",
    "    clf_name = '{}_{}_{}.pickle'.format(clf_type, color_map, time.strftime('%m-%d-%H-%M'))\n",
    "    dump_classifier(clf, clf_name)\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a single function that can extract features using hog sub-sampling and make predictions\n",
    "# Return windows wherein a car is detected\n",
    "def find_windows(img, ystart, ystop, scale, clf, scaler, orient, pix_per_cell, cell_per_block, cells_per_step, spatial_size, hist_bins):\n",
    "    # Ensure image is scaled between (0,255)\n",
    "    img = img_as_ubyte(img)\n",
    "    \n",
    "    windows_hat = []\n",
    "    \n",
    "    # Restrit image to area of interest\n",
    "    img_tosearch = rescale_intensity(img[ystart:ystop,:,:])\n",
    "    # Convert colorspace given color_map parameter\n",
    "    if color_map != 'RGB':\n",
    "        ctrans_tosearch = rgb_convert(img_tosearch, color_map)\n",
    "    # Scale image to search over different window sizes\n",
    "    # scale = 1; window = 64x64\n",
    "    # scale = 1.5; window = 96x96\n",
    "    # scale = 2; window = 128x128\n",
    "    if scale != 1:\n",
    "        imshape = ctrans_tosearch.shape\n",
    "        ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "\n",
    "    ch1 = ctrans_tosearch[:,:,0]\n",
    "    ch2 = ctrans_tosearch[:,:,1]\n",
    "    ch3 = ctrans_tosearch[:,:,2]\n",
    "\n",
    "    # Define blocks and steps as above\n",
    "    nxblocks = (ch1.shape[1] // pix_per_cell) - cell_per_block + 1\n",
    "    nyblocks = (ch1.shape[0] // pix_per_cell) - cell_per_block + 1\n",
    "    nfeat_per_block = orient*cell_per_block**2\n",
    "\n",
    "    # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "    window = 64\n",
    "    nblocks_per_window = (window // pix_per_cell) - cell_per_block + 1\n",
    "\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step\n",
    "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step\n",
    "\n",
    "    # Compute individual channel HOG features for the entire image\n",
    "    hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "\n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            ypos = yb*cells_per_step\n",
    "            xpos = xb*cells_per_step\n",
    "            # Extract HOG for this patch\n",
    "            hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel()\n",
    "            hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel()\n",
    "            hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel()\n",
    "            hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "\n",
    "            xleft = xpos*pix_per_cell\n",
    "            ytop = ypos*pix_per_cell\n",
    "            \n",
    "            subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "\n",
    "            # Get color features\n",
    "            spatial_features = bin_spatial(subimg, size=spatial_size)\n",
    "            hist_features = color_hist(subimg, nbins=hist_bins)\n",
    "\n",
    "            # Scale features and make a prediction\n",
    "            test_features = scaler.transform(np.hstack((spatial_features, hist_features, hog_features)).reshape(1, -1))\n",
    "            test_prediction = clf.predict(test_features)\n",
    "            \n",
    "            # If the prediction is True, add window to windows_hat\n",
    "            if test_prediction[0] == 1:\n",
    "                xbox_left = np.int(xleft*scale)\n",
    "                ytop_draw = np.int(ytop*scale)\n",
    "                win_draw = np.int(window*scale)\n",
    "                \n",
    "                window_i = ((xbox_left, ytop_draw+ystart), (xbox_left+win_draw, ytop_draw+win_draw+ystart))\n",
    "                windows_hat.append(window_i)\n",
    "                \n",
    "    return windows_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Draw bounding boxes on image\n",
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=4):\n",
    "    # Make a copy of the image\n",
    "    imcopy = np.copy(img)\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes:\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "    # Return the image copy with boxes drawn\n",
    "    return imcopy\n",
    "    \n",
    "# Add heat to pixels within bboxes of bbox_list\n",
    "def add_heat(heatmap, bbox_list):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "\n",
    "    # Return updated heatmap\n",
    "    return heatmap\n",
    "\n",
    "# Apply threshold to heatmap\n",
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap < threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap\n",
    "\n",
    "# Draw labeled bounding boxes on image\n",
    "# given output from scipy labels function which identifies distinct areas of rectangles\n",
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 4)\n",
    "    # Return the image\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vehicle_tracker_pipeline(frame):\n",
    "    \n",
    "    # define smoothing factor\n",
    "    n = smth_fctr\n",
    "    \n",
    "    # Initialize list of windows (bboxes) wherein a car was detected\n",
    "    windows_hat = []\n",
    "    \n",
    "    for scale in scales_dict.keys():\n",
    "        # Use different ystart, ystop & cells_per_step depending on scale (i.e. window size)\n",
    "        ystart = scales_dict[scale][0]\n",
    "        ystop = scales_dict[scale][1]\n",
    "        cells_per_step = scales_dict[scale][2]\n",
    "        # Find windows and append to windows_hat\n",
    "        windows_hat_i = find_windows(frame, ystart, ystop, scale, clf, scaler, orient, pix_per_cell, cell_per_block, cells_per_step, spatial_size, hist_bins)\n",
    "        for i in windows_hat_i:\n",
    "            windows_hat.append(i)\n",
    "\n",
    "    # Generate heatmap given bounding boxes (windows_hat) wherein a car was detected\n",
    "    heatmap = np.zeros(frame.shape[:2])\n",
    "    heatmap = add_heat(heatmap, windows_hat)\n",
    "    \n",
    "    # Add heatmap to array of recent heatmaps for smoothing\n",
    "    car_tracker.recent_heatmaps.append(heatmap)\n",
    "    car_tracker.recent_heatmaps = car_tracker.recent_heatmaps[-n:]\n",
    "    heatmap_avg = np.average(car_tracker.recent_heatmaps, axis = 0)\n",
    "    \n",
    "    # Apply threshold to heatmap\n",
    "    heatmap_thresh = apply_threshold(heatmap_avg, threshold = heat_thresh)\n",
    "\n",
    "    # Use labels function from scipy to detect separate vehicles\n",
    "    labels = label(heatmap_thresh)\n",
    "    if labels[1] == 0:\n",
    "        car_tracker.recent_heatmaps = []\n",
    "    \n",
    "    # Generate output image by drawing bounding boxes (via labels) on copy of image\n",
    "    out_img = draw_labeled_bboxes(np.copy(frame), labels)\n",
    "    \n",
    "    return out_img\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PARAMETERS ###\n",
    "\n",
    "# High level parameters defining I/O\n",
    "testing = False\n",
    "processed_images = False\n",
    "# Color Map Choices: RGB, HSV, LUV, YCbCr\n",
    "color_map = 'YCbCr'\n",
    "clf_type = 'xgb'\n",
    "\n",
    "# Parameters for Histogram of Oriented Gradients features\n",
    "# scales_dict format :: scale: (ystart, ystop, cells_per_step)\n",
    "scales_dict = {\n",
    "    1: (400, 464, 1),\n",
    "    1.5: (400, 528, 1),\n",
    "    2: (400, 592, 2)\n",
    "}\n",
    "orient=12\n",
    "pix_per_cell=8\n",
    "cell_per_block=2\n",
    "\n",
    "\n",
    "# Parameter for bin spatial feature\n",
    "spatial_size = (32, 32)\n",
    "\n",
    "# Parameters for color histogram feature\n",
    "hist_bins=32\n",
    "hist_range=(0, 256)\n",
    "\n",
    "# Heatmap threshold\n",
    "heat_thresh = 1.75\n",
    "\n",
    "# Smoothing Factor\n",
    "smth_fctr = 12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features loaded from pickle\n",
      "training for validation...\n",
      "xgb clf fit in 516.24 s\n",
      "Accuracy = 0.9923986486486487\n",
      "f1 Score = 0.9922346850733391\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      0.99      1801\n",
      "        1.0       1.00      0.99      0.99      1751\n",
      "\n",
      "avg / total       0.99      0.99      0.99      3552\n",
      "\n",
      "training for final...\n",
      "xgb final clf fit in 653.16 s\n",
      "Classifier dumped to clfs/scaler_YCbCr.pickle\n",
      "Classifier dumped to clfs/xgb_YCbCr_06-29-12-42.pickle\n"
     ]
    }
   ],
   "source": [
    "train_clf_pipeline()\n",
    "\n",
    "# Load scaler and classifier from train_set trained images \n",
    "scaler = load_clf('scaler_{}.pickle'.format(color_map))\n",
    "clf = load_clf('{}_{}.pickle'.format(clf_type, color_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_name = 'result.mp4'\n",
    "suboutput_name = 'subclip_result.mp4'\n",
    "\n",
    "clip = VideoFileClip(\"project_video.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If testing, process subclip\n",
    "if testing:\n",
    "\n",
    "    global car_tracker\n",
    "    car_tracker = Tracker()\n",
    "    \n",
    "    subclip = clip.subclip(5, 15)\n",
    "    suboutput = subclip.fl_image(vehicle_tracker_pipeline)\n",
    "    %time suboutput.write_videofile(suboutput_name, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video result.mp4\n",
      "[MoviePy] Writing video result.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [1:33:42<00:04,  4.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: result.mp4 \n",
      "\n",
      "CPU times: user 5h 34min 10s, sys: 7min 41s, total: 5h 41min 52s\n",
      "Wall time: 1h 33min 44s\n"
     ]
    }
   ],
   "source": [
    "# If not testing, process whole clip\n",
    "if not testing:\n",
    "\n",
    "    global car_tracker\n",
    "    car_tracker = Tracker()\n",
    "\n",
    "    output = clip.fl_image(vehicle_tracker_pipeline) \n",
    "    %time output.write_videofile(output_name, audio=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
